{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "284423e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from delta import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "#  Create a spark session with Delta\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"DeltaTutorial\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "# Create spark context\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efa9bd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_db = spark.sql('CREATE DATABASE IF NOT EXISTS f1_demo LOCATION \"file:/E:/unused/Udemy/Spark_practice/raw/Delta lake/db\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74465de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql('DROP DATABASE f1_demo CASCADE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "027adc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+----------+---------------+--------------+----+----+------------+------+------+--------+-------------+------------+------+----+--------+--------+-----------+\n",
      "|constructorId|driverId|fastestLap|fastestLapSpeed|fastestLapTime|grid|laps|milliseconds|number|points|position|positionOrder|positionText|raceId|rank|resultId|statusId|       time|\n",
      "+-------------+--------+----------+---------------+--------------+----+----+------------+------+------+--------+-------------+------------+------+----+--------+--------+-----------+\n",
      "|          131|       1|        44|        207.235|      1:34.015|   2|  56|     5523897|    44|    25|       1|            1|           1|  1052|   4|   24966|       1|1:32:03.897|\n",
      "|            9|     830|        41|        208.984|      1:33.228|   1|  56|     5524642|    33|    18|       2|            2|           2|  1052|   2|   24967|       1|     +0.745|\n",
      "+-------------+--------+----------+---------------+--------------+----+----+------------+------+------+--------+-------------+------------+------+----+--------+--------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_df = spark.read.json(r'E:\\unused\\Udemy\\Spark_practice\\raw\\incremental_load_data\\raw files\\2021-03-28\\results.json')\n",
    "results_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28f75af",
   "metadata": {},
   "source": [
    "https://docs.delta.io/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08503254",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.write.format('delta').mode('overwrite').saveAsTable('f1_demo.results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d91144bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.write.format('delta').mode('overwrite').save('file/result_delta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b1fc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('CREATE TABLE f1_demo.results_delta_ext USING delta LOCATION \"file\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2357fccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+----------+---------------+--------------+----+----+------------+------+------+--------+-------------+------------+------+----+--------+--------+-----------+\n",
      "|constructorId|driverId|fastestLap|fastestLapSpeed|fastestLapTime|grid|laps|milliseconds|number|points|position|positionOrder|positionText|raceId|rank|resultId|statusId|       time|\n",
      "+-------------+--------+----------+---------------+--------------+----+----+------------+------+------+--------+-------------+------------+------+----+--------+--------+-----------+\n",
      "|          131|       1|        44|        207.235|      1:34.015|   2|  56|     5523897|    44|    25|       1|            1|           1|  1052|   4|   24966|       1|1:32:03.897|\n",
      "|            9|     830|        41|        208.984|      1:33.228|   1|  56|     5524642|    33|    18|       2|            2|           2|  1052|   2|   24967|       1|     +0.745|\n",
      "+-------------+--------+----------+---------------+--------------+----+----+------------+------+------+--------+-------------+------------+------+----+--------+--------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df = spark.read.format('delta').load(\"file/result_delta\")\n",
    "result_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9fe203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.write.format('delta').mode('overwrite').partitionBy('constructorId').saveAsTable('f1_demo.results_partition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3720b8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+----------+---------------+--------------+----+----+------------+------+------+--------+-------------+------------+------+----+--------+--------+-----------+\n",
      "|constructorId|driverId|fastestLap|fastestLapSpeed|fastestLapTime|grid|laps|milliseconds|number|points|position|positionOrder|positionText|raceId|rank|resultId|statusId|       time|\n",
      "+-------------+--------+----------+---------------+--------------+----+----+------------+------+------+--------+-------------+------------+------+----+--------+--------+-----------+\n",
      "|          131|       1|        44|        207.235|      1:34.015|   2|  56|     5523897|    44|    25|       1|            1|           1|  1052|   4|   24966|       1|1:32:03.897|\n",
      "|          131|     822|        56|        211.566|      1:32.090|   3|  56|     5561280|    77|    16|       3|            3|           3|  1052|   1|   24968|       1|    +37.383|\n",
      "+-------------+--------+----------+---------------+--------------+----+----+------------+------+------+--------+-------------+------------+------+----+--------+--------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark.sql('SHOW PARTITIONS f1_demo.results_partition').show()\n",
    "result_df = spark.sql('SELECT * FROM f1_demo.results_partition')\n",
    "result_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984687a4",
   "metadata": {},
   "source": [
    "## UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b2f2c04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|num_affected_rows|\n",
      "+-----------------+\n",
      "|               10|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('UPDATE f1_demo.results_partition SET points = 11 - position where position<=10').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "219dfb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+----------+---------------+--------------+----+----+------------+------+------+--------+-------------+------------+------+----+--------+--------+-----------+\n",
      "|constructorId|driverId|fastestLap|fastestLapSpeed|fastestLapTime|grid|laps|milliseconds|number|points|position|positionOrder|positionText|raceId|rank|resultId|statusId|       time|\n",
      "+-------------+--------+----------+---------------+--------------+----+----+------------+------+------+--------+-------------+------------+------+----+--------+--------+-----------+\n",
      "|          131|       1|        44|        207.235|      1:34.015|   2|  56|     5523897|    44|    20|       1|            1|           1|  1052|   4|   24966|       1|1:32:03.897|\n",
      "|            9|     830|        41|        208.984|      1:33.228|   1|  56|     5524642|    33|    19|       2|            2|           2|  1052|   2|   24967|       1|     +0.745|\n",
      "+-------------+--------+----------+---------------+--------------+----+----+------------+------+------+--------+-------------+------------+------+----+--------+--------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from delta.tables import DeltaTable\n",
    "deltaTable =  DeltaTable.forPath(spark, \"file/result_delta\")\n",
    "deltaTable.update('position <= 10',{'points':'21-position'})\n",
    "result_df = spark.read.format('delta').load(\"file/result_delta\")\n",
    "result_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccf9eae",
   "metadata": {},
   "source": [
    "# DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9d54cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      12|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('DELETE from f1_demo.results_partition WHERE position>10')\n",
    "result_df = spark.sql('SELECT count(*) FROM f1_demo.results_partition')\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14682b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+----------+---------------+--------------+----+----+------------+------+------+--------+-------------+------------+------+----+--------+--------+-----------+\n",
      "|constructorId|driverId|fastestLap|fastestLapSpeed|fastestLapTime|grid|laps|milliseconds|number|points|position|positionOrder|positionText|raceId|rank|resultId|statusId|       time|\n",
      "+-------------+--------+----------+---------------+--------------+----+----+------------+------+------+--------+-------------+------------+------+----+--------+--------+-----------+\n",
      "|          131|       1|        44|        207.235|      1:34.015|   2|  56|     5523897|    44|    20|       1|            1|           1|  1052|   4|   24966|       1|1:32:03.897|\n",
      "|            9|     830|        41|        208.984|      1:33.228|   1|  56|     5524642|    33|    19|       2|            2|           2|  1052|   2|   24967|       1|     +0.745|\n",
      "|          131|     822|        56|        211.566|      1:32.090|   3|  56|     5561280|    77|    18|       3|            3|           3|  1052|   1|   24968|       1|    +37.383|\n",
      "|            1|     846|        38|        206.398|      1:34.396|   7|  56|     5570363|     4|    17|       4|            4|           4|  1052|   6|   24969|       1|    +46.466|\n",
      "|            9|     815|        44|        207.334|      1:33.970|   0|  56|     5575944|    11|    16|       5|            5|           5|  1052|   3|   24970|       1|    +52.047|\n",
      "|            6|     844|        39|        205.112|      1:34.988|   4|  56|     5582987|    16|    15|       6|            6|           6|  1052|  11|   24971|       1|    +59.090|\n",
      "|            1|     817|        36|        205.233|      1:34.932|   6|  56|     5589901|     3|    14|       7|            7|           7|  1052|  10|   24972|       1|    +66.004|\n",
      "|            6|     832|        48|        206.151|      1:34.509|   8|  56|     5590997|    55|    13|       8|            8|           8|  1052|   7|   24973|       1|    +67.100|\n",
      "|          213|     852|        38|        205.603|      1:34.761|  13|  56|     5609589|    22|    12|       9|            9|           9|  1052|   8|   24974|       1|    +85.692|\n",
      "|          117|     840|        31|        205.378|      1:34.865|  10|  56|     5610610|    18|    11|      10|           10|          10|  1052|   9|   24975|       1|    +86.713|\n",
      "|          214|       4|        31|        202.816|      1:36.063|   9|  32|          \\N|    14|     0|      \\N|           19|           R|  1052|  17|   24984|      23|         \\N|\n",
      "|          210|     853|        \\N|             \\N|            \\N|  19|   0|          \\N|     9|     0|      \\N|           20|           R|  1052|   0|   24985|       3|         \\N|\n",
      "+-------------+--------+----------+---------------+--------------+----+----+------------+------+------+--------+-------------+------------+------+----+--------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deltaTable.delete(\"position>10\")\n",
    "result_df = spark.read.format('delta').load(\"file/result_delta\")\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e600328",
   "metadata": {},
   "source": [
    "## MERGE/ UPSERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21cf6988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+----------+\n",
      "|driverId|       dob| forename|   surname|\n",
      "+--------+----------+---------+----------+\n",
      "|       1|1985-01-07|    Lewis|  Hamilton|\n",
      "|       2|1977-05-10|     Nick|  Heidfeld|\n",
      "|       3|1985-06-27|     Nico|   Rosberg|\n",
      "|       4|1981-07-29| Fernando|    Alonso|\n",
      "|       5|1981-10-19|   Heikki|Kovalainen|\n",
      "|       6|1985-01-11|   Kazuki|  Nakajima|\n",
      "|       7|1979-02-28|Sébastien|  Bourdais|\n",
      "|       8|1979-10-17|     Kimi| Räikkönen|\n",
      "|       9|1984-12-07|   Robert|    Kubica|\n",
      "|      10|1982-03-18|     Timo|     Glock|\n",
      "+--------+----------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drivers_day1_df = spark.read \\\n",
    ".option(\"inferSchema\", True) \\\n",
    ".json(r'E:\\unused\\Udemy\\Spark_practice\\raw\\incremental_load_data\\raw files\\2021-03-28\\drivers.json') \\\n",
    ".filter(\"driverId <= 10\") \\\n",
    ".select(\"driverId\", \"dob\", \"name.forename\", \"name.surname\")\n",
    "\n",
    "drivers_day1_df.createOrReplaceTempView(\"drivers_day1\")\n",
    "drivers_day1_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "116529ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+----------+\n",
      "|driverId|       dob| forename|   surname|\n",
      "+--------+----------+---------+----------+\n",
      "|       6|1985-01-11|   KAZUKI|  NAKAJIMA|\n",
      "|       7|1979-02-28|SÉBASTIEN|  BOURDAIS|\n",
      "|       8|1979-10-17|     KIMI| RÄIKKÖNEN|\n",
      "|       9|1984-12-07|   ROBERT|    KUBICA|\n",
      "|      10|1982-03-18|     TIMO|     GLOCK|\n",
      "|      11|1977-01-28|   TAKUMA|      SATO|\n",
      "|      12|1985-07-25|   NELSON|PIQUET JR.|\n",
      "|      13|1981-04-25|   FELIPE|     MASSA|\n",
      "|      14|1971-03-27|    DAVID| COULTHARD|\n",
      "|      15|1974-07-13|    JARNO|    TRULLI|\n",
      "+--------+----------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drivers_day2_df = spark.read \\\n",
    ".option(\"inferSchema\", True) \\\n",
    ".json(r'E:\\unused\\Udemy\\Spark_practice\\raw\\incremental_load_data\\raw files\\2021-03-28\\drivers.json') \\\n",
    ".filter(\"driverId BETWEEN 6 AND 15\") \\\n",
    ".select(\"driverId\", \"dob\", upper(\"name.forename\").alias(\"forename\"), upper(\"name.surname\").alias(\"surname\"))\n",
    "\n",
    "drivers_day2_df.createOrReplaceTempView(\"drivers_day2\")\n",
    "drivers_day2_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a1212b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+----------+\n",
      "|driverId|       dob| forename|   surname|\n",
      "+--------+----------+---------+----------+\n",
      "|       1|1985-01-07|    LEWIS|  HAMILTON|\n",
      "|       2|1977-05-10|     NICK|  HEIDFELD|\n",
      "|       3|1985-06-27|     NICO|   ROSBERG|\n",
      "|       4|1981-07-29| FERNANDO|    ALONSO|\n",
      "|       5|1981-10-19|   HEIKKI|KOVALAINEN|\n",
      "|      16|1983-01-11|   ADRIAN|     SUTIL|\n",
      "|      17|1976-08-27|     MARK|    WEBBER|\n",
      "|      18|1980-01-19|   JENSON|    BUTTON|\n",
      "|      19|1979-04-18|  ANTHONY|  DAVIDSON|\n",
      "|      20|1987-07-03|SEBASTIAN|    VETTEL|\n",
      "+--------+----------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drivers_day3_df = spark.read \\\n",
    ".option(\"inferSchema\", True) \\\n",
    ".json(r'E:\\unused\\Udemy\\Spark_practice\\raw\\incremental_load_data\\raw files\\2021-03-28\\drivers.json') \\\n",
    ".filter(\"driverId BETWEEN 1 AND 5 OR driverId BETWEEN 16 AND 20\") \\\n",
    ".select(\"driverId\", \"dob\", upper(\"name.forename\").alias(\"forename\"), upper(\"name.surname\").alias(\"surname\"))\n",
    "\n",
    "drivers_day3_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a962698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('CREATE TABLE IF NOT EXISTS f1_demo.drivers_merge ( driverId INT, dob DATE, forename STRING,  surname STRING, createdDate DATE,  updatedDate DATE ) USING DELTA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90ea77b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+----------------+-----------------+\n",
      "|num_affected_rows|num_updated_rows|num_deleted_rows|num_inserted_rows|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "|               10|               0|               0|               10|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('MERGE INTO f1_demo.drivers_merge tgt USING drivers_day1 upd ON tgt.driverId=upd.driverId WHEN MATCHED THEN UPDATE SET tgt.dob = upd.dob,tgt.forename = upd.forename,tgt.surname = upd.surname,tgt.updatedDate = current_timestamp WHEN NOT MATCHED THEN INSERT (driverId, dob, forename,surname,createdDate ) VALUES (driverId, dob, forename,surname, current_timestamp)').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd0d3ac",
   "metadata": {},
   "source": [
    "`MERGE INTO target\n",
    "USING source\n",
    "ON source.key = target.key\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET *\n",
    "WHEN NOT MATCHED THEN\n",
    "  INSERT *\n",
    "WHEN NOT MATCHED BY SOURCE\n",
    "  DELETE`  \n",
    " WHEN NOT MATCHED BY SOURCE clause to UPDATE or DELETE records in the target table that do not have corresponding records in the source table. We recommend adding an optional conditional clause to avoid fully rewriting the target table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "555b37e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+----------+-----------+-----------+\n",
      "|driverId|       dob| forename|   surname|createdDate|updatedDate|\n",
      "+--------+----------+---------+----------+-----------+-----------+\n",
      "|       7|1979-02-28|Sébastien|  Bourdais| 2024-02-10|       null|\n",
      "|       6|1985-01-11|   Kazuki|  Nakajima| 2024-02-10|       null|\n",
      "|       9|1984-12-07|   Robert|    Kubica| 2024-02-10|       null|\n",
      "|       5|1981-10-19|   Heikki|Kovalainen| 2024-02-10|       null|\n",
      "|       1|1985-01-07|    Lewis|  Hamilton| 2024-02-10|       null|\n",
      "|      10|1982-03-18|     Timo|     Glock| 2024-02-10|       null|\n",
      "|       3|1985-06-27|     Nico|   Rosberg| 2024-02-10|       null|\n",
      "|       8|1979-10-17|     Kimi| Räikkönen| 2024-02-10|       null|\n",
      "|       2|1977-05-10|     Nick|  Heidfeld| 2024-02-10|       null|\n",
      "|       4|1981-07-29| Fernando|    Alonso| 2024-02-10|       null|\n",
      "+--------+----------+---------+----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * FROM f1_demo.drivers_merge').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecc5c317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+----------------+-----------------+\n",
      "|num_affected_rows|num_updated_rows|num_deleted_rows|num_inserted_rows|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "|               10|               5|               0|                5|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('MERGE INTO f1_demo.drivers_merge tgt USING drivers_day2 upd ON tgt.driverId=upd.driverId WHEN MATCHED THEN UPDATE SET tgt.dob = upd.dob,tgt.forename = upd.forename,tgt.surname = upd.surname,tgt.updatedDate = current_timestamp WHEN NOT MATCHED THEN INSERT (driverId, dob, forename,surname,createdDate ) VALUES (driverId, dob, forename,surname, current_timestamp)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3dc7cf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+----------+-----------+-----------+\n",
      "|driverId|       dob| forename|   surname|createdDate|updatedDate|\n",
      "+--------+----------+---------+----------+-----------+-----------+\n",
      "|       1|1985-01-07|    Lewis|  Hamilton| 2024-02-10|       null|\n",
      "|       2|1977-05-10|     Nick|  Heidfeld| 2024-02-10|       null|\n",
      "|       3|1985-06-27|     Nico|   Rosberg| 2024-02-10|       null|\n",
      "|       4|1981-07-29| Fernando|    Alonso| 2024-02-10|       null|\n",
      "|       5|1981-10-19|   Heikki|Kovalainen| 2024-02-10|       null|\n",
      "|       6|1985-01-11|   KAZUKI|  NAKAJIMA| 2024-02-10| 2024-02-10|\n",
      "|       7|1979-02-28|SÉBASTIEN|  BOURDAIS| 2024-02-10| 2024-02-10|\n",
      "|       8|1979-10-17|     KIMI| RÄIKKÖNEN| 2024-02-10| 2024-02-10|\n",
      "|       9|1984-12-07|   ROBERT|    KUBICA| 2024-02-10| 2024-02-10|\n",
      "|      10|1982-03-18|     TIMO|     GLOCK| 2024-02-10| 2024-02-10|\n",
      "|      11|1977-01-28|   TAKUMA|      SATO| 2024-02-10|       null|\n",
      "|      12|1985-07-25|   NELSON|PIQUET JR.| 2024-02-10|       null|\n",
      "|      13|1981-04-25|   FELIPE|     MASSA| 2024-02-10|       null|\n",
      "|      14|1971-03-27|    DAVID| COULTHARD| 2024-02-10|       null|\n",
      "|      15|1974-07-13|    JARNO|    TRULLI| 2024-02-10|       null|\n",
      "+--------+----------+---------+----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * FROM f1_demo.drivers_merge').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cac899ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "deltaTablePeople = DeltaTable.forPath(spark, r\"E:/unused/Udemy/Spark_practice/raw/Delta lake/db/drivers_merge\")\n",
    "\n",
    "deltaTablePeople.alias('tgt') \\\n",
    "  .merge(\n",
    "    drivers_day3_df.alias('upd'),\n",
    "    \"tgt.driverId = upd.driverId\"\n",
    "  ) \\\n",
    "  .whenMatchedUpdate(set =\n",
    "    {\n",
    "      \"dob\" : \"upd.dob\",\n",
    "      \"forename\" : \"upd.forename\",\n",
    "      \"surname\" : \"upd.surname\",\n",
    "      \"updatedDate\": \"current_timestamp()\"\n",
    "    }\n",
    "  ) \\\n",
    "  .whenNotMatchedInsert(values =\n",
    "    {\n",
    "      \"driverId\": \"upd.driverId\",\n",
    "      \"dob\": \"upd.dob\",\n",
    "      \"forename\" : \"upd.forename\", \n",
    "      \"surname\" : \"upd.surname\", \n",
    "      \"createdDate\": \"current_timestamp()\"\n",
    "    }\n",
    "  ) \\\n",
    "  .execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45522299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+----------+-----------+-----------+\n",
      "|driverId|       dob| forename|   surname|createdDate|updatedDate|\n",
      "+--------+----------+---------+----------+-----------+-----------+\n",
      "|       1|1985-01-07|    LEWIS|  HAMILTON| 2024-02-10| 2024-02-10|\n",
      "|       2|1977-05-10|     NICK|  HEIDFELD| 2024-02-10| 2024-02-10|\n",
      "|       3|1985-06-27|     NICO|   ROSBERG| 2024-02-10| 2024-02-10|\n",
      "|       4|1981-07-29| FERNANDO|    ALONSO| 2024-02-10| 2024-02-10|\n",
      "|       5|1981-10-19|   HEIKKI|KOVALAINEN| 2024-02-10| 2024-02-10|\n",
      "|       6|1985-01-11|   KAZUKI|  NAKAJIMA| 2024-02-10| 2024-02-10|\n",
      "|       7|1979-02-28|SÉBASTIEN|  BOURDAIS| 2024-02-10| 2024-02-10|\n",
      "|       8|1979-10-17|     KIMI| RÄIKKÖNEN| 2024-02-10| 2024-02-10|\n",
      "|       9|1984-12-07|   ROBERT|    KUBICA| 2024-02-10| 2024-02-10|\n",
      "|      10|1982-03-18|     TIMO|     GLOCK| 2024-02-10| 2024-02-10|\n",
      "|      11|1977-01-28|   TAKUMA|      SATO| 2024-02-10|       null|\n",
      "|      12|1985-07-25|   NELSON|PIQUET JR.| 2024-02-10|       null|\n",
      "|      13|1981-04-25|   FELIPE|     MASSA| 2024-02-10|       null|\n",
      "|      14|1971-03-27|    DAVID| COULTHARD| 2024-02-10|       null|\n",
      "|      15|1974-07-13|    JARNO|    TRULLI| 2024-02-10|       null|\n",
      "|      16|1983-01-11|   ADRIAN|     SUTIL| 2024-02-10|       null|\n",
      "|      17|1976-08-27|     MARK|    WEBBER| 2024-02-10|       null|\n",
      "|      18|1980-01-19|   JENSON|    BUTTON| 2024-02-10|       null|\n",
      "|      19|1979-04-18|  ANTHONY|  DAVIDSON| 2024-02-10|       null|\n",
      "|      20|1987-07-03|SEBASTIAN|    VETTEL| 2024-02-10|       null|\n",
      "+--------+----------+---------+----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * FROM f1_demo.drivers_merge').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d9cfa0",
   "metadata": {},
   "source": [
    "## History Of Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce2b610c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+------+--------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation   |operationParameters                                                                                                                                                                                |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|3      |2024-02-10 21:05:17.96 |null  |null    |MERGE       |{predicate -> (CAST(tgt.driverId AS BIGINT) = upd.driverId), matchedPredicates -> [{\"actionType\":\"update\"}], notMatchedPredicates -> [{\"actionType\":\"insert\"}], notMatchedBySourcePredicates -> []}|null|null    |null     |2          |Serializable  |false        |{numTargetRowsCopied -> 10, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 2280, numTargetBytesRemoved -> 2151, numTargetRowsMatchedUpdated -> 5, executionTimeMs -> 1434, numTargetRowsInserted -> 5, numTargetRowsMatchedDeleted -> 0, scanTimeMs -> 838, numTargetRowsUpdated -> 5, numOutputRows -> 20, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 10, numTargetFilesRemoved -> 1, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 502}|null        |Apache-Spark/3.3.4 Delta-Lake/2.3.0|\n",
      "|2      |2024-02-10 21:05:13.505|null  |null    |MERGE       |{predicate -> (CAST(tgt.driverId AS BIGINT) = upd.driverId), matchedPredicates -> [{\"actionType\":\"update\"}], notMatchedPredicates -> [{\"actionType\":\"insert\"}], notMatchedBySourcePredicates -> []}|null|null    |null     |1          |Serializable  |false        |{numTargetRowsCopied -> 5, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 2151, numTargetBytesRemoved -> 1949, numTargetRowsMatchedUpdated -> 5, executionTimeMs -> 1716, numTargetRowsInserted -> 5, numTargetRowsMatchedDeleted -> 0, scanTimeMs -> 938, numTargetRowsUpdated -> 5, numOutputRows -> 15, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 10, numTargetFilesRemoved -> 1, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 697} |null        |Apache-Spark/3.3.4 Delta-Lake/2.3.0|\n",
      "|1      |2024-02-10 21:05:07.999|null  |null    |MERGE       |{predicate -> (CAST(tgt.driverId AS BIGINT) = upd.driverId), matchedPredicates -> [{\"actionType\":\"update\"}], notMatchedPredicates -> [{\"actionType\":\"insert\"}], notMatchedBySourcePredicates -> []}|null|null    |null     |0          |Serializable  |false        |{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 1949, numTargetBytesRemoved -> 0, numTargetRowsMatchedUpdated -> 0, executionTimeMs -> 2568, numTargetRowsInserted -> 10, numTargetRowsMatchedDeleted -> 0, scanTimeMs -> 1290, numTargetRowsUpdated -> 0, numOutputRows -> 10, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 10, numTargetFilesRemoved -> 0, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 951}  |null        |Apache-Spark/3.3.4 Delta-Lake/2.3.0|\n",
      "|0      |2024-02-10 21:04:56.971|null  |null    |CREATE TABLE|{isManaged -> true, description -> null, partitionBy -> [], properties -> {}}                                                                                                                      |null|null    |null     |null       |Serializable  |true         |{}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |null        |Apache-Spark/3.3.4 Delta-Lake/2.3.0|\n",
      "+-------+-----------------------+------+--------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('DESCRIBE HISTORY f1_demo.drivers_merge').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "749f497a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+----------+-----------+-----------+\n",
      "|driverId|       dob| forename|   surname|createdDate|updatedDate|\n",
      "+--------+----------+---------+----------+-----------+-----------+\n",
      "|       1|1985-01-07|    Lewis|  Hamilton| 2024-02-10|       null|\n",
      "|       2|1977-05-10|     Nick|  Heidfeld| 2024-02-10|       null|\n",
      "|       3|1985-06-27|     Nico|   Rosberg| 2024-02-10|       null|\n",
      "|       4|1981-07-29| Fernando|    Alonso| 2024-02-10|       null|\n",
      "|       5|1981-10-19|   Heikki|Kovalainen| 2024-02-10|       null|\n",
      "|       6|1985-01-11|   KAZUKI|  NAKAJIMA| 2024-02-10| 2024-02-10|\n",
      "|       7|1979-02-28|SÉBASTIEN|  BOURDAIS| 2024-02-10| 2024-02-10|\n",
      "|       8|1979-10-17|     KIMI| RÄIKKÖNEN| 2024-02-10| 2024-02-10|\n",
      "|       9|1984-12-07|   ROBERT|    KUBICA| 2024-02-10| 2024-02-10|\n",
      "|      10|1982-03-18|     TIMO|     GLOCK| 2024-02-10| 2024-02-10|\n",
      "|      11|1977-01-28|   TAKUMA|      SATO| 2024-02-10|       null|\n",
      "|      12|1985-07-25|   NELSON|PIQUET JR.| 2024-02-10|       null|\n",
      "|      13|1981-04-25|   FELIPE|     MASSA| 2024-02-10|       null|\n",
      "|      14|1971-03-27|    DAVID| COULTHARD| 2024-02-10|       null|\n",
      "|      15|1974-07-13|    JARNO|    TRULLI| 2024-02-10|       null|\n",
      "+--------+----------+---------+----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * FROM f1_demo.drivers_merge VERSION AS OF 2').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35a73dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+----------+-----------+-----------+\n",
      "|driverId|       dob| forename|   surname|createdDate|updatedDate|\n",
      "+--------+----------+---------+----------+-----------+-----------+\n",
      "|       1|1985-01-07|    Lewis|  Hamilton| 2024-02-10|       null|\n",
      "|       2|1977-05-10|     Nick|  Heidfeld| 2024-02-10|       null|\n",
      "|       3|1985-06-27|     Nico|   Rosberg| 2024-02-10|       null|\n",
      "|       4|1981-07-29| Fernando|    Alonso| 2024-02-10|       null|\n",
      "|       5|1981-10-19|   Heikki|Kovalainen| 2024-02-10|       null|\n",
      "|       6|1985-01-11|   KAZUKI|  NAKAJIMA| 2024-02-10| 2024-02-10|\n",
      "|       7|1979-02-28|SÉBASTIEN|  BOURDAIS| 2024-02-10| 2024-02-10|\n",
      "|       8|1979-10-17|     KIMI| RÄIKKÖNEN| 2024-02-10| 2024-02-10|\n",
      "|       9|1984-12-07|   ROBERT|    KUBICA| 2024-02-10| 2024-02-10|\n",
      "|      10|1982-03-18|     TIMO|     GLOCK| 2024-02-10| 2024-02-10|\n",
      "|      11|1977-01-28|   TAKUMA|      SATO| 2024-02-10|       null|\n",
      "|      12|1985-07-25|   NELSON|PIQUET JR.| 2024-02-10|       null|\n",
      "|      13|1981-04-25|   FELIPE|     MASSA| 2024-02-10|       null|\n",
      "|      14|1971-03-27|    DAVID| COULTHARD| 2024-02-10|       null|\n",
      "|      15|1974-07-13|    JARNO|    TRULLI| 2024-02-10|       null|\n",
      "+--------+----------+---------+----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * FROM f1_demo.drivers_merge TIMESTAMP AS OF \"2024-02-10 21:05:13.505\"').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b62ed0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+----------+-----------+-----------+\n",
      "|driverId|       dob| forename|   surname|createdDate|updatedDate|\n",
      "+--------+----------+---------+----------+-----------+-----------+\n",
      "|       1|1985-01-07|    Lewis|  Hamilton| 2024-02-10|       null|\n",
      "|       2|1977-05-10|     Nick|  Heidfeld| 2024-02-10|       null|\n",
      "|       3|1985-06-27|     Nico|   Rosberg| 2024-02-10|       null|\n",
      "|       4|1981-07-29| Fernando|    Alonso| 2024-02-10|       null|\n",
      "|       5|1981-10-19|   Heikki|Kovalainen| 2024-02-10|       null|\n",
      "|       6|1985-01-11|   KAZUKI|  NAKAJIMA| 2024-02-10| 2024-02-10|\n",
      "|       7|1979-02-28|SÉBASTIEN|  BOURDAIS| 2024-02-10| 2024-02-10|\n",
      "|       8|1979-10-17|     KIMI| RÄIKKÖNEN| 2024-02-10| 2024-02-10|\n",
      "|       9|1984-12-07|   ROBERT|    KUBICA| 2024-02-10| 2024-02-10|\n",
      "|      10|1982-03-18|     TIMO|     GLOCK| 2024-02-10| 2024-02-10|\n",
      "|      11|1977-01-28|   TAKUMA|      SATO| 2024-02-10|       null|\n",
      "|      12|1985-07-25|   NELSON|PIQUET JR.| 2024-02-10|       null|\n",
      "|      13|1981-04-25|   FELIPE|     MASSA| 2024-02-10|       null|\n",
      "|      14|1971-03-27|    DAVID| COULTHARD| 2024-02-10|       null|\n",
      "|      15|1974-07-13|    JARNO|    TRULLI| 2024-02-10|       null|\n",
      "+--------+----------+---------+----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"delta\").\\\n",
    "           option(\"timestampAsOf\", \"2024-02-10 21:05:13.505\").\\\n",
    "           load(r\"E:/unused/Udemy/Spark_practice/raw/Delta lake/db/drivers_merge\").show()\n",
    "# instead of timestampAsOf we can give versionAsOf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19842655",
   "metadata": {},
   "source": [
    "## VACCUM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a43092",
   "metadata": {},
   "source": [
    "You can remove files no longer referenced by a Delta table and are older than the retention threshold by running the vacuum command on the table. vacuum is not triggered automatically. The default retention threshold for the files is 7 days. if you don't run the VACUUM operation periodically on a Delta table, the metadata associated with the table may become large over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f461a546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                path|\n",
      "+--------------------+\n",
      "|file:/E:/unused/U...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('VACUUM f1_demo.drivers_merge').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a088f9f0",
   "metadata": {},
   "source": [
    "Scenario: need to delete the history versions of the table (According to GDPR if a person asks to delete his/her personal data from a server we need to delete it. so keeping the history versions is punishable according to law)  \n",
    "can not delete history version for a single record, the versions of table as a whole should be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e96d659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                path|\n",
      "+--------------------+\n",
      "|file:/E:/unused/U...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SET spark.databricks.delta.retentionDurationCheck.enabled = false')\n",
    "spark.sql('VACUUM f1_demo.drivers_merge RETAIN 0 HOURS').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5068f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('SELECT * FROM f1_demo.drivers_merge TIMESTAMP AS OF \"2024-02-10 21:05:13.505\"').show()\n",
    "#This will give a error as all the history versions are deletd\n",
    "#but we can see the HISTORY of the table but can't query from the table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0846ea",
   "metadata": {},
   "source": [
    "#### if deleted by mistake to restore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84294fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('DELETE FROM f1_demo.drivers_merge WHERE driverId = 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c00afbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+----------------+-----------------+\n",
      "|num_affected_rows|num_updated_rows|num_deleted_rows|num_inserted_rows|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "|                1|               0|               0|                1|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('MERGE INTO f1_demo.drivers_merge tgt USING (SELECT * FROM f1_demo.drivers_merge VERSION AS OF 3) src ON tgt.driverId = src.driverId WHEN NOT MATCHED THEN INSERT *').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6146d7",
   "metadata": {},
   "source": [
    "## change retention period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbec5441",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_table = DeltaTable.forPath(spark, \"E:/unused/Udemy/Spark_practice/raw/Delta lake/db/drivers_merge\")\n",
    "delta_table.logRetentionDuration= \" 5 minutes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a75abd",
   "metadata": {},
   "source": [
    "Due to log entry cleanup, instances can arise where you cannot time travel to a version that is less than the retention interval. Delta Lake requires all consecutive log entries since the previous checkpoint to time travel to a particular version. For example, with a table initially consisting of log entries for versions [0, 19] and a checkpoint at verison 10, if the log entry for version 0 is cleaned up, then you cannot time travel to versions [1, 9]. Increasing the table property delta.logRetentionDuration can help avoid these situations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c186cc4c",
   "metadata": {},
   "source": [
    "\n",
    "Delta logs, also known as transaction logs, are created and used in Delta Lake to record all changes made to Delta tables.\n",
    "When you perform operations such as inserts, updates, deletes, merges, or schema changes on a Delta table, Delta Lake generates corresponding Delta log entries.\n",
    "* These log entries capture metadata about the operations, including the affected data files, the type of operation (e.g., insert, update, delete), timestamps, transaction identifiers, and other relevant information.\n",
    "* Delta logs are stored as immutable, append-only files in the _delta_log directory within the Delta table's storage location.\n",
    "* Write-Ahead Logging (WAL) ensures that changes are first recorded in the transaction log before being applied to the data files, ensuring durability and recoverability in case of failures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebf3b7a",
   "metadata": {},
   "source": [
    "## Convert Parquet to Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29700483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('CREATE TABLE IF NOT EXISTS f1_demo.drivers_convert_to_delta ( driverId INT, dob DATE, forename STRING,  surname STRING, createdDate DATE,  updatedDate DATE ) USING PARQUET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b046abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"E:/unused/Udemy/Spark_practice/raw/Delta lake/db/drivers_merge\")\n",
    "df.write.format('parquet').mode('overwrite').saveAsTable('f1_demo.drivers_convert_to_delta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "462d9fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('CONVERT TO DELTA f1_demo.drivers_convert_to_delta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfdc6dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.table(\"f1_demo.drivers_convert_to_delta\")\n",
    "df.write.format(\"parquet\").save(\"E:/unused/Udemy/Spark_practice/raw/Delta lake/db/drivers_convert_to_delta_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5661a5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('CONVERT TO DELTA parquet.`E:/unused/Udemy/Spark_practice/raw/Delta lake/db/drivers_convert_to_delta_new`')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6a0f34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
