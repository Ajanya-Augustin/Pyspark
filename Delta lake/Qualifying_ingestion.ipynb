{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a16b409",
   "metadata": {},
   "source": [
    "## INCREMENTAL LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97be2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_date = '2021-03-21'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5fce1c",
   "metadata": {},
   "source": [
    "<div style=\"max-width:1400px;margin-center: auto\">\n",
    "<img src=\"images\\qualifying.png\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a8ab789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from delta import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "#  Create a spark session with Delta\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"dbcreation\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "# Create spark context\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3eb772c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql.functions import current_timestamp,count,desc,lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04236aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualifying_schema = StructType(fields=[StructField(\"qualifyId\", IntegerType(), False),\n",
    "                                      StructField(\"raceId\", IntegerType(), True),\n",
    "                                      StructField(\"driverId\", StringType(), True),\n",
    "                                      StructField(\"constructorId\", IntegerType(), True),\n",
    "                                      StructField(\"number\", IntegerType(), True),\n",
    "                                      StructField(\"position\", IntegerType(), True),\n",
    "                                      StructField(\"q1\", StringType(), True),\n",
    "                                      StructField(\"q2\", StringType(), True),\n",
    "                                      StructField(\"q3\", StringType(), True)\n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee9e66c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+--------+-------------+------+--------+--------+--------+--------+\n",
      "|qualifyId|raceId|driverId|constructorId|number|position|      q1|      q2|      q3|\n",
      "+---------+------+--------+-------------+------+--------+--------+--------+--------+\n",
      "|        1|    18|       1|            1|    22|       1|1:26.572|1:25.187|1:26.714|\n",
      "|        2|    18|       9|            2|     4|       2|1:26.103|1:25.315|1:26.869|\n",
      "+---------+------+--------+-------------+------+--------+--------+--------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qualifying_df = spark.read.json(f'raw files\\\\{file_date}\\\\qualifying', multiLine = True, schema = qualifying_schema)\n",
    "qualifying_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49f7c8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = qualifying_df.withColumnRenamed(\"qualifyId\", \"qualify_id\") \\\n",
    "                        .withColumnRenamed(\"raceId\", \"race_id\") \\\n",
    "                        .withColumnRenamed(\"driverId\", \"driver_id\") \\\n",
    "                        .withColumnRenamed(\"constructorId\", \"constructor_id\") \\\n",
    "                        .withColumn(\"ingestion_date\", current_timestamp())\\\n",
    "                        .withColumn(\"file_date\",lit(file_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f843d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"common_functions.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea6b5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_condition = \"tgt.qualify_id = src.qualify_id AND tgt.race_id = src.race_id\"\n",
    "merge_delta_data(final_df, 'default', 'qualifying', 'E:/unused/Udemy/Spark_practice/raw/Delta%20lake/spark-warehouse',merge_condition,'race_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58fae825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_file1_count for each raceId : \n",
      "+-------+--------+\n",
      "|race_id|count(1)|\n",
      "+-------+--------+\n",
      "|   1053|      20|\n",
      "|   1052|      20|\n",
      "|   1047|      20|\n",
      "|   1046|      20|\n",
      "|   1045|      20|\n",
      "|   1044|      20|\n",
      "|   1043|      20|\n",
      "|   1042|      20|\n",
      "|   1041|      20|\n",
      "|   1040|      20|\n",
      "|   1039|      20|\n",
      "|   1038|      20|\n",
      "|   1037|      20|\n",
      "|   1036|      20|\n",
      "|   1035|      20|\n",
      "|   1034|      20|\n",
      "|   1033|      20|\n",
      "|   1032|      20|\n",
      "|   1031|      20|\n",
      "|   1030|      20|\n",
      "+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql('SELECT * FROM default.qualifying')\n",
    "print('df_file1_count for each raceId : ')\n",
    "df.groupBy('race_id').agg(count('*')).orderBy(desc('race_id')).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
