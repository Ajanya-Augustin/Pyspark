{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fcc5b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from delta import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "#  Create a spark session with Delta\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"dbcreation\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "# Create spark context\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c00a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_processed = spark.sql('CREATE DATABASE IF NOT EXISTS f1_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49396c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_trans = spark.sql('CREATE DATABASE IF NOT EXISTS f1_trans LOCATION \"file:/E:/unused/Udemy/Spark_practice/raw/Delta lake/f1_trans\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a713e55",
   "metadata": {},
   "source": [
    "circuits, races, constructors, drivers - full load scenario. Overwrite data with the new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062812ce",
   "metadata": {},
   "source": [
    "Results, Pitstops, LapTimes and Qualifying files which contain only the data related to that race in the file being received for that week.  \n",
    "Not overwrite but append the data to the Data Lake and in case of failures and we rerun a file, we would want to replace only that files data rather than the entire Data Lake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5105b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql('DROP TABLE f1_processed.qualifying')\n",
    "# spark.sql('DROP TABLE f1_processed.pit_stops')\n",
    "# spark.sql('DROP TABLE f1_processed.lap_times')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5df34086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------------------------------------------------------------------------------+\n",
      "|info_name     |info_value                                                                             |\n",
      "+--------------+---------------------------------------------------------------------------------------+\n",
      "|Namespace Name|f1_processed                                                                           |\n",
      "|Comment       |                                                                                       |\n",
      "|Location      |file:/E:/unused/Udemy/Spark_practice/raw/Delta%2520lake/spark-warehouse/f1_processed.db|\n",
      "|Owner         |user                                                                                   |\n",
      "|Properties    |                                                                                       |\n",
      "+--------------+---------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('DESCRIBE DATABASE EXTENDED f1_processed').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c6b5c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Database(name='default', description='default database', locationUri='file:/E:/unused/Udemy/Spark_practice/raw/Delta%20lake/spark-warehouse'),\n",
       " Database(name='f1_processed', description='', locationUri='file:/E:/unused/Udemy/Spark_practice/raw/Delta%20lake/spark-warehouse/f1_processed.db'),\n",
       " Database(name='f1_trans', description='', locationUri='file:/E:/unused/Udemy/Spark_practice/raw/Delta lake/f1_trans')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listDatabases()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
