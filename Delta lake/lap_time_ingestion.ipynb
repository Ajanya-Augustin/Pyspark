{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bb51394",
   "metadata": {},
   "source": [
    "## INCREMENTAL LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b7ee618",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_date = '2021-03-21'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a4602c",
   "metadata": {},
   "source": [
    "<div style=\"max-width:1400px;margin-center: auto\">\n",
    "<img src=\"images\\laptime.png\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1ac7e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from delta import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "#  Create a spark session with Delta\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"dbcreation\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "# Create spark context\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4e94246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, IntegerType, StringType\n",
    "from pyspark.sql.functions import col, current_timestamp,desc, lit, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b95b4ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_time_schema = StructType( fields = [StructField(\"raceId\", IntegerType(), False),\n",
    "                                        StructField(\"driverId\", IntegerType(), True),\n",
    "                                        StructField(\"lap\", IntegerType(), True),\n",
    "                                        StructField(\"position\", IntegerType(), True),\n",
    "                                        StructField(\"time\", StringType(), True),\n",
    "                                        StructField(\"milliseconds\", IntegerType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b83781d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---+--------+--------+------------+\n",
      "|raceId|driverId|lap|position|    time|milliseconds|\n",
      "+------+--------+---+--------+--------+------------+\n",
      "|   841|      20|  1|       1|1:38.109|       98109|\n",
      "|   841|      20|  2|       1|1:33.006|       93006|\n",
      "+------+--------+---+--------+--------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lap_time_df = spark.read.csv(f'raw files\\\\{file_date}\\\\lap_times', schema = lap_time_schema)\n",
    "lap_time_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "744e7c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490904"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lap_time_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f033ff98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---+--------+--------+------------+--------------------+----------+\n",
      "|race_id|driver_id|lap|position|    time|milliseconds|      ingestion_date| file_date|\n",
      "+-------+---------+---+--------+--------+------------+--------------------+----------+\n",
      "|    841|       20|  1|       1|1:38.109|       98109|2024-02-11 15:13:...|2021-03-21|\n",
      "|    841|       20|  2|       1|1:33.006|       93006|2024-02-11 15:13:...|2021-03-21|\n",
      "+-------+---------+---+--------+--------+------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lap_time_fnl_df = lap_time_df.withColumnRenamed(\"raceId\",\"race_id\").\\\n",
    "                              withColumnRenamed(\"driverId\",\"driver_id\").\\\n",
    "                              withColumn(\"ingestion_date\",current_timestamp()).\\\n",
    "                              withColumn(\"file_date\",lit(file_date))\n",
    "lap_time_fnl_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c037a51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"common_functions.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ffb461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_condition = \"tgt.race_id = src.race_id AND tgt.driver_id = src.driver_id AND tgt.lap = src.lap AND tgt.race_id = src.race_id\"\n",
    "merge_delta_data(lap_time_fnl_df, 'default', 'lap_times', 'E:/unused/Udemy/Spark_practice/raw/Delta%20lake/spark-warehouse',merge_condition,'race_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862828ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql('SELECT * FROM default.lap_times')\n",
    "print('df_file1_count for each raceId : ')\n",
    "df.groupBy('race_id').agg(count('*')).orderBy(desc('race_id')).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
