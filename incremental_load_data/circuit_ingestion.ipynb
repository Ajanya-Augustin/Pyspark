{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2afe0ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_date = '2021-03-21'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc4c667",
   "metadata": {},
   "source": [
    "## Requirement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e54f60f",
   "metadata": {},
   "source": [
    "<div style=\"max-width:1400px;margin-center: auto\">\n",
    "<img src=\"images\\circuit.png\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58803e2",
   "metadata": {},
   "source": [
    "## Insert Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98b81908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('local') \\\n",
    "    .appName(\"circuit\") \\\n",
    "    .config(\"spark.sql.catalogImplementation\", \"hive\") \\\n",
    "    .getOrCreate()\n",
    "import os\n",
    "os.chdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc001635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "825a07fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuits_schema = StructType(fields=[StructField(\"circuitId\", IntegerType(), False),\n",
    "                                     StructField(\"circuitRef\", StringType(), True),\n",
    "                                     StructField(\"name\", StringType(), True),\n",
    "                                     StructField(\"location\", StringType(), True),\n",
    "                                     StructField(\"country\", StringType(), True),\n",
    "                                     StructField(\"lat\", DoubleType(), True),\n",
    "                                     StructField(\"lng\", DoubleType(), True),\n",
    "                                     StructField(\"alt\", IntegerType(), True),\n",
    "                                     StructField(\"url\", StringType(), True)\n",
    "])\n",
    "#even though nullable for circuit id is given false it is not applied,\n",
    "#to apply this we should use other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e91cb85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_df = spark.read.csv(f'raw files\\\\{file_date}\\\\circuits.csv'\n",
    "                            ,header=True,schema =circuits_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1d4b32",
   "metadata": {},
   "source": [
    "### Select only the required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45fce6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a38ac7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuits_selected_df = circuit_df.select(col(\"circuitId\"), col(\"circuitRef\"), col(\"name\"), col(\"location\"), col(\"country\"), col(\"lat\"), col(\"lng\"), col(\"alt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d991664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+--------------------+------------+---------+--------+-------+---+\n",
      "|circuitId| circuitRef|                name|    location|  country|     lat|    lng|alt|\n",
      "+---------+-----------+--------------------+------------+---------+--------+-------+---+\n",
      "|        1|albert_park|Albert Park Grand...|   Melbourne|Australia|-37.8497|144.968| 10|\n",
      "|        2|     sepang|Sepang Internatio...|Kuala Lumpur| Malaysia| 2.76083|101.738| 18|\n",
      "+---------+-----------+--------------------+------------+---------+--------+-------+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "circuits_selected_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee09bf0",
   "metadata": {},
   "source": [
    "### Rename The columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d282bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuits_renamed_df = circuits_selected_df.withColumnRenamed(\"circuitId\", \"circuit_id\") \\\n",
    ".withColumnRenamed(\"circuitRef\", \"circuit_ref\") \\\n",
    ".withColumnRenamed(\"lat\", \"latitude\") \\\n",
    ".withColumnRenamed(\"lng\", \"longitude\") \\\n",
    ".withColumnRenamed(\"alt\", \"altitude\") \\\n",
    ".withColumn('file_date',lit(file_date))\n",
    "#When using .withColumn to add a new column to a DataFrame, you might use lit to assign a constant value to that column for all rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3a229dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------------------+------------+---------+--------+---------+--------+----------+\n",
      "|circuit_id|circuit_ref|                name|    location|  country|latitude|longitude|altitude| file_date|\n",
      "+----------+-----------+--------------------+------------+---------+--------+---------+--------+----------+\n",
      "|         1|albert_park|Albert Park Grand...|   Melbourne|Australia|-37.8497|  144.968|      10|2021-03-21|\n",
      "|         2|     sepang|Sepang Internatio...|Kuala Lumpur| Malaysia| 2.76083|  101.738|      18|2021-03-21|\n",
      "+----------+-----------+--------------------+------------+---------+--------+---------+--------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "circuits_renamed_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed97776",
   "metadata": {},
   "source": [
    "### Add the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3b51672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4942c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuits_final_df = circuits_renamed_df.withColumn(\"ingestion_date\", current_timestamp()) \n",
    "# col name and value of column as parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e13690ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# circuits_final_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24dd441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# circuits_final_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6303b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# circuits_final_df = circuits_renamed_df.withColumn(\"env\", lit(\"prod\")) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87b14700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# circuits_final_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d34dcb",
   "metadata": {},
   "source": [
    "### write data as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59628b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuits_renamed_df.write.mode('overwrite').format('delta').saveAsTable('f1_processed.circuits')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
