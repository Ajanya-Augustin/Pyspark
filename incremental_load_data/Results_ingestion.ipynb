{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "66457a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_date = '2021-03-28'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3bd21f",
   "metadata": {},
   "source": [
    "<div style=\"max-width:1400px;margin-center: auto\">\n",
    "<img src=\"images\\results.png\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "987c4c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('local') \\\n",
    "    .appName(\"result\") \\\n",
    "    .config(\"spark.sql.catalogImplementation\", \"hive\") \\\n",
    "    .getOrCreate()\n",
    "import os\n",
    "os.chdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fd0eee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType, FloatType, StringType, StructField, StructType\n",
    "from pyspark.sql.functions import col, current_timestamp,count,max,lit,desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d6c25be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_schema = StructType(fields=[StructField(\"resultId\", IntegerType(), False),\n",
    "                                    StructField(\"raceId\", IntegerType(), True),\n",
    "                                    StructField(\"driverId\", IntegerType(), True),\n",
    "                                    StructField(\"constructorId\", IntegerType(), True),\n",
    "                                    StructField(\"number\", IntegerType(), True),\n",
    "                                    StructField(\"grid\", IntegerType(), True),\n",
    "                                    StructField(\"position\", IntegerType(), True),\n",
    "                                    StructField(\"positionText\", StringType(), True),\n",
    "                                    StructField(\"positionOrder\", IntegerType(), True),\n",
    "                                    StructField(\"points\", FloatType(), True),\n",
    "                                    StructField(\"laps\", IntegerType(), True),\n",
    "                                    StructField(\"time\", StringType(), True),\n",
    "                                    StructField(\"milliseconds\", IntegerType(), True),\n",
    "                                    StructField(\"fastestLap\", IntegerType(), True),\n",
    "                                    StructField(\"rank\", IntegerType(), True),\n",
    "                                    StructField(\"fastestLapTime\", StringType(), True),\n",
    "                                    StructField(\"fastestLapSpeed\", FloatType(), True),\n",
    "                                    StructField(\"statusId\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0045e84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------+-------------+------+----+--------+------------+-------------+------+----+-----------+------------+----------+----+--------------+---------------+--------+\n",
      "|resultId|raceId|driverId|constructorId|number|grid|position|positionText|positionOrder|points|laps|       time|milliseconds|fastestLap|rank|fastestLapTime|fastestLapSpeed|statusId|\n",
      "+--------+------+--------+-------------+------+----+--------+------------+-------------+------+----+-----------+------------+----------+----+--------------+---------------+--------+\n",
      "|   24966|  1052|       1|          131|    44|   2|       1|           1|            1|  25.0|  56|1:32:03.897|     5523897|        44|   4|      1:34.015|        207.235|       1|\n",
      "|   24967|  1052|     830|            9|    33|   1|       2|           2|            2|  18.0|  56|     +0.745|     5524642|        41|   2|      1:33.228|        208.984|       1|\n",
      "+--------+------+--------+-------------+------+----+--------+------------+-------------+------+----+-----------+------------+----------+----+--------------+---------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_df = spark.read.json(f'raw files\\\\{file_date}\\\\results.json', schema = results_schema)\n",
    "results_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "526864c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut_over count of distinct_race_id :  1035\n",
      "df_file1 count of distinct_race_id  :  1\n",
      "cut_over_count for each raceId : \n",
      "+------+--------+\n",
      "|raceId|count(1)|\n",
      "+------+--------+\n",
      "|   148|      22|\n",
      "|   463|      29|\n",
      "|   471|      32|\n",
      "+------+--------+\n",
      "only showing top 3 rows\n",
      "\n",
      "df_file1_count for each raceId : \n",
      "+------+--------+\n",
      "|raceId|count(1)|\n",
      "+------+--------+\n",
      "|  1052|      20|\n",
      "+------+--------+\n",
      "\n",
      "cut_over_max of raceId : \n",
      "+-----------+\n",
      "|max(raceId)|\n",
      "+-----------+\n",
      "|       1047|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cut_over_df = spark.read.json(f'raw files\\\\2021-03-21\\\\results.json', schema = results_schema)\n",
    "df_file1 = spark.read.json(f'raw files\\\\2021-03-28\\\\results.json', schema = results_schema)\n",
    "print('cut_over count of distinct_race_id : ',cut_over_df.select('raceId').distinct().count())\n",
    "print('df_file1 count of distinct_race_id  : ',df_file1.select('raceId').distinct().count())\n",
    "print('cut_over_count for each raceId : ')\n",
    "cut_over_df.groupBy('raceId').agg(count('*')).show(3)\n",
    "print('df_file1_count for each raceId : ')\n",
    "df_file1.groupBy('raceId').agg(count('*')).show()\n",
    "print('cut_over_max of raceId : ')\n",
    "cut_over_df.agg(max('raceId')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "26962fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+---------+--------------+------+----+--------+-------------+--------------+------+----+-----------+------------+-----------+----+----------------+-----------------+--------+--------------------+----------+\n",
      "|result_id|race_id|driver_id|constructor_id|number|grid|position|position_text|position_order|points|laps|       time|milliseconds|fastest_lap|rank|fastest_lap_time|fastest_lap_speed|statusId|      ingestion_date| file_date|\n",
      "+---------+-------+---------+--------------+------+----+--------+-------------+--------------+------+----+-----------+------------+-----------+----+----------------+-----------------+--------+--------------------+----------+\n",
      "|    24966|   1052|        1|           131|    44|   2|       1|            1|             1|  25.0|  56|1:32:03.897|     5523897|         44|   4|        1:34.015|          207.235|       1|2024-01-31 19:44:...|2021-03-28|\n",
      "|    24967|   1052|      830|             9|    33|   1|       2|            2|             2|  18.0|  56|     +0.745|     5524642|         41|   2|        1:33.228|          208.984|       1|2024-01-31 19:44:...|2021-03-28|\n",
      "+---------+-------+---------+--------------+------+----+--------+-------------+--------------+------+----+-----------+------------+-----------+----+----------------+-----------------+--------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_with_columns_df = results_df.withColumnRenamed(\"resultId\", \"result_id\") \\\n",
    "                                    .withColumnRenamed(\"raceId\", \"race_id\") \\\n",
    "                                    .withColumnRenamed(\"driverId\", \"driver_id\") \\\n",
    "                                    .withColumnRenamed(\"constructorId\", \"constructor_id\") \\\n",
    "                                    .withColumnRenamed(\"positionText\", \"position_text\") \\\n",
    "                                    .withColumnRenamed(\"positionOrder\", \"position_order\") \\\n",
    "                                    .withColumnRenamed(\"fastestLap\", \"fastest_lap\") \\\n",
    "                                    .withColumnRenamed(\"fastestLapTime\", \"fastest_lap_time\") \\\n",
    "                                    .withColumnRenamed(\"fastestLapSpeed\", \"fastest_lap_speed\") \\\n",
    "                                    .withColumn(\"ingestion_date\", current_timestamp())\\\n",
    "                                    .withColumn(\"file_date\",lit(file_date))\n",
    "results_with_columns_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9ebc1524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+---------+--------------+------+----+--------+-------------+--------------+------+----+-----------+------------+-----------+----+----------------+-----------------+--------------------+----------+\n",
      "|result_id|race_id|driver_id|constructor_id|number|grid|position|position_text|position_order|points|laps|       time|milliseconds|fastest_lap|rank|fastest_lap_time|fastest_lap_speed|      ingestion_date| file_date|\n",
      "+---------+-------+---------+--------------+------+----+--------+-------------+--------------+------+----+-----------+------------+-----------+----+----------------+-----------------+--------------------+----------+\n",
      "|    24966|   1052|        1|           131|    44|   2|       1|            1|             1|  25.0|  56|1:32:03.897|     5523897|         44|   4|        1:34.015|          207.235|2024-01-31 19:44:...|2021-03-28|\n",
      "|    24967|   1052|      830|             9|    33|   1|       2|            2|             2|  18.0|  56|     +0.745|     5524642|         41|   2|        1:33.228|          208.984|2024-01-31 19:44:...|2021-03-28|\n",
      "+---------+-------+---------+--------------+------+----+--------+-------------+--------------+------+----+-----------+------------+-----------+----+----------------+-----------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_final_df = results_with_columns_df.drop(col(\"statusId\"))\n",
    "results_final_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee92b16",
   "metadata": {},
   "source": [
    "## Method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffc4243",
   "metadata": {},
   "source": [
    "collect () :collect takes all the data and put it into the driver node's memory.so use it carefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5bd8af9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for race_id in results_final_df.select('race_id').distinct().collect():\n",
    "    if (spark._jsparkSession.catalog().tableExists(\"f1_processed.results\")):\n",
    "        spark.sql(f\"ALTER TABLE f1_processed.results DROP IF EXISTS PARTITION (race_id ={race_id.race_id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "df98f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_final_df.write.mode(\"append\").partitionBy('race_id').format('parquet').saveAsTable('f1_processed.results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82912163",
   "metadata": {},
   "source": [
    "# Method 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b25b187",
   "metadata": {},
   "source": [
    "there is no way to specify the order of columns being inserted , but Spark expects the last column in the list to be the partitioned column when you're InsertInto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "95100f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['result_id',\n",
       " 'race_id',\n",
       " 'driver_id',\n",
       " 'constructor_id',\n",
       " 'number',\n",
       " 'grid',\n",
       " 'position',\n",
       " 'position_text',\n",
       " 'position_order',\n",
       " 'points',\n",
       " 'laps',\n",
       " 'time',\n",
       " 'milliseconds',\n",
       " 'fastest_lap',\n",
       " 'rank',\n",
       " 'fastest_lap_time',\n",
       " 'fastest_lap_speed',\n",
       " 'ingestion_date',\n",
       " 'file_date']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b9a4a3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_final_df = results_final_df.select('result_id',\n",
    "'driver_id',\n",
    "'constructor_id',\n",
    "'number',\n",
    "'grid',\n",
    "'position',\n",
    "'position_text',\n",
    "'position_order',\n",
    "'points',\n",
    "'laps',\n",
    "'time',\n",
    "'milliseconds',\n",
    "'fastest_lap',\n",
    "'rank',\n",
    "'fastest_lap_time',\n",
    "'fastest_lap_speed',\n",
    "'ingestion_date',\n",
    "'file_date',\n",
    "'race_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1499c61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\",\"dynamic\")\n",
    "# else will overwrite all the partition. if set to dynamic only rewrites the partition with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c6221b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (spark._jsparkSession.catalog().tableExists('f1_processed.results')):\n",
    "    results_final_df.write.mode(\"overwrite\").insertInto('f1_processed.results')\n",
    "else:\n",
    "    results_final_df.write.mode(\"overwrite\").partitionBy(partition_column).format(\"parquet\").saveAsTable(f\"{db_name}.{table_name}\")\n",
    "# else will only run in the first attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b0278a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_file1_count for each raceId : \n",
      "+-------+--------+\n",
      "|race_id|count(1)|\n",
      "+-------+--------+\n",
      "|   1053|      20|\n",
      "|   1052|      20|\n",
      "|   1047|      20|\n",
      "|   1046|      20|\n",
      "|   1045|      20|\n",
      "|   1044|      20|\n",
      "|   1043|      20|\n",
      "|   1042|      20|\n",
      "|   1041|      20|\n",
      "|   1040|      20|\n",
      "|   1039|      20|\n",
      "|   1038|      20|\n",
      "|   1037|      20|\n",
      "|   1036|      20|\n",
      "|   1035|      20|\n",
      "|   1034|      20|\n",
      "|   1033|      20|\n",
      "|   1032|      20|\n",
      "|   1031|      20|\n",
      "|   1030|      20|\n",
      "+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql('SELECT * FROM f1_processed.results')\n",
    "print('df_file1_count for each raceId : ')\n",
    "df.groupBy('race_id').agg(count('*')).orderBy(desc('race_id')).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
