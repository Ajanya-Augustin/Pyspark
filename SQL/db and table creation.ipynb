{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f2de650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "conf = SparkConf().setAppName('DB_creation').setMaster('local')\n",
    "sc = SparkContext(conf = conf)\n",
    "# spark = SparkSession(sc)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"example\") \\\n",
    "    .config(\"spark.sql.catalogImplementation\", \"hive\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "011d898f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('CREATE DATABASE IF NOT EXISTS demo').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9bdc75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|     demo|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SHOW DATABASES').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebd6ce64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+\n",
      "|     info_name|          info_value|\n",
      "+--------------+--------------------+\n",
      "|Namespace Name|                demo|\n",
      "|       Comment|                    |\n",
      "|      Location|file:/E:/unused/U...|\n",
      "|         Owner|                user|\n",
      "|    Properties|                    |\n",
      "+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('DESCRIBE DATABASE EXTENDED demo').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44e7e4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+-------------------+----------------+--------------+-------------+------------------+-------+----+-----------+---------+------+--------+\n",
      "|race_year|        race_name|          race_date|circuit_location|   driver_name|driver_number|driver_nationality|   team|grid|fastest_lap|race_time|points|position|\n",
      "+---------+-----------------+-------------------+----------------+--------------+-------------+------------------+-------+----+-----------+---------+------+--------+\n",
      "|     1974|German Grand Prix|1974-08-04 00:00:00|         Nürburg|Clay Regazzoni|         null|             Swiss|Ferrari|   2|       null|1:41:35.0|   9.0|       1|\n",
      "|     1974|German Grand Prix|1974-08-04 00:00:00|         Nürburg|Jody Scheckter|         null|     South African|Tyrrell|   4|       null|    +50.7|   6.0|       2|\n",
      "+---------+-----------------+-------------------+----------------+--------------+-------------+------------------+-------+----+-----------+---------+------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "race_result_df = spark.read.parquet(r'E:\\unused\\Udemy\\Spark_practice\\raw\\presentation\\race_result',inferSchema = True)\n",
    "race_result_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82bbe11",
   "metadata": {},
   "source": [
    "### craete managed/internal table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d410a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_result_df.write.mode('overwrite').format('parquet').saveAsTable('demo.race_result_tb_py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "052def08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|            col_name|           data_type|comment|\n",
      "+--------------------+--------------------+-------+\n",
      "|           race_year|                 int|   null|\n",
      "|           race_name|              string|   null|\n",
      "|           race_date|           timestamp|   null|\n",
      "|    circuit_location|              string|   null|\n",
      "|         driver_name|              string|   null|\n",
      "|       driver_number|                 int|   null|\n",
      "|  driver_nationality|              string|   null|\n",
      "|                team|              string|   null|\n",
      "|                grid|                 int|   null|\n",
      "|         fastest_lap|                 int|   null|\n",
      "|           race_time|              string|   null|\n",
      "|              points|               float|   null|\n",
      "|            position|                 int|   null|\n",
      "|                    |                    |       |\n",
      "|# Detailed Table ...|                    |       |\n",
      "|            Database|                demo|       |\n",
      "|               Table|   race_result_tb_py|       |\n",
      "|               Owner|                user|       |\n",
      "|        Created Time|Mon Jan 15 13:47:...|       |\n",
      "|         Last Access|             UNKNOWN|       |\n",
      "+--------------------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('USE demo')\n",
    "spark.sql('DESCRIBE TABLE EXTENDED demo.race_result_tb_py ').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79fe53b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('CREATE TABLE demo.race_result_tb_sql as SELECT * FROM demo.race_result_tb_py').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02efaa25",
   "metadata": {},
   "source": [
    "### create external table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ecf2c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_result_df.write.format('parquet').option('path',r'E:\\unused\\Udemy\\Spark_practice\\raw\\presentation\\ext_tb_py').saveAsTable('demo.race_result_tb_py_ext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52b6d094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- race_year: integer (nullable = true)\n",
      " |-- race_name: string (nullable = true)\n",
      " |-- race_date: timestamp (nullable = true)\n",
      " |-- circuit_location: string (nullable = true)\n",
      " |-- driver_name: string (nullable = true)\n",
      " |-- driver_number: integer (nullable = true)\n",
      " |-- driver_nationality: string (nullable = true)\n",
      " |-- team: string (nullable = true)\n",
      " |-- grid: integer (nullable = true)\n",
      " |-- fastest_lap: integer (nullable = true)\n",
      " |-- race_time: string (nullable = true)\n",
      " |-- points: float (nullable = true)\n",
      " |-- position: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "race_result_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38064af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('CREATE TABLE demo.race_result_tb_sql_ext( race_year INT,race_name STRING, race_date TIMESTAMP, circuit_location STRING, driver_name string, driver_number INT, driver_nationality STRING, team STRING, grid INT, fastest_lap INT, race_time STRING, points FLOAT, position INT) USING parquet LOCATION \"file:/E:/unused/Udemy/Spark_practice/raw/presentation/ext_tb_sql\"')\n",
    "#only metadata is created for the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b44518e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|     demo|   race_result_tb_py|      false|\n",
      "|     demo|race_result_tb_py...|      false|\n",
      "|     demo|  race_result_tb_sql|      false|\n",
      "|     demo|race_result_tb_sq...|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SHOW TABLES IN demo').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86af393e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('INSERT INTO demo.race_result_tb_sql_ext SELECT * FROM demo.race_result_tb_py_ext WHERE race_year=2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9946e0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     340|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT count(*) FROM demo.race_result_tb_sql_ext').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b15b88f",
   "metadata": {},
   "source": [
    "### drop tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37d01b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|     demo|   race_result_tb_py|      false|\n",
      "|     demo|race_result_tb_py...|      false|\n",
      "|     demo|  race_result_tb_sql|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('DROP TABLE demo.race_result_tb_sql_ext')\n",
    "spark.sql('SHOW TABLES IN demo').show()\n",
    "# table is dropped but file is not deleted in external table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a5f263",
   "metadata": {},
   "source": [
    "<div style=\"max-width:1400px;margin-center: auto\">\n",
    "<img src=\"images\\external table.png\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c71610e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|     demo|   race_result_tb_py|      false|\n",
      "|     demo|race_result_tb_py...|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('DROP TABLE demo.race_result_tb_sql')\n",
    "spark.sql('SHOW TABLES IN demo').show()\n",
    "# table is dropped and file is deleted in internal table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e128ca",
   "metadata": {},
   "source": [
    "<div style=\"max-width:1400px;margin-center: auto\">\n",
    "<img src=\"images\\managed table.png\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8886238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|     demo|\n",
      "|   f1_raw|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SHOW DATABASES').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c365de7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
